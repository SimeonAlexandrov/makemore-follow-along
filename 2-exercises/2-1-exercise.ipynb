{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('../names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "\n",
    "chars = ['.'] + chars \n",
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding 2 char combinations in a dict\n",
    "stoi_2 = {}\n",
    "n = 0\n",
    "for ch1 in chars:\n",
    "    for ch2 in chars:\n",
    "        stoi_2[f'{ch1}{ch2}'] = n\n",
    "        n += 1\n",
    "len(stoi_2.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos_2 = {i:s for s,i in stoi_2.items()}\n",
    "itos_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples: 196113\n"
     ]
    }
   ],
   "source": [
    "# create the dataset\n",
    "xs, ys = [], []\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi_2[f'{ch1}{ch2}']\n",
    "        ix2 = stoi[ch3]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print(f'number of examples: {num}')\n",
    "\n",
    "# init the 'network'\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((729,27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9221363067626953\n",
      "2.9183037281036377\n",
      "2.91451096534729\n",
      "2.910757064819336\n",
      "2.9070420265197754\n",
      "2.903364896774292\n",
      "2.8997249603271484\n",
      "2.8961219787597656\n",
      "2.892554759979248\n",
      "2.889024019241333\n",
      "2.885528326034546\n",
      "2.8820672035217285\n",
      "2.8786404132843018\n",
      "2.8752474784851074\n",
      "2.8718881607055664\n",
      "2.8685615062713623\n",
      "2.865267515182495\n",
      "2.8620052337646484\n",
      "2.8587746620178223\n",
      "2.8555750846862793\n",
      "2.8524060249328613\n",
      "2.8492679595947266\n",
      "2.846158981323242\n",
      "2.8430802822113037\n",
      "2.8400301933288574\n",
      "2.837008476257324\n",
      "2.8340160846710205\n",
      "2.8310511112213135\n",
      "2.828113555908203\n",
      "2.8252031803131104\n",
      "2.8223202228546143\n",
      "2.8194632530212402\n",
      "2.8166322708129883\n",
      "2.8138277530670166\n",
      "2.8110482692718506\n",
      "2.8082940578460693\n",
      "2.8055646419525146\n",
      "2.8028597831726074\n",
      "2.8001790046691895\n",
      "2.7975223064422607\n",
      "2.794888973236084\n",
      "2.792279005050659\n",
      "2.789691686630249\n",
      "2.7871274948120117\n",
      "2.784585475921631\n",
      "2.7820651531219482\n",
      "2.779567003250122\n",
      "2.777090311050415\n",
      "2.774634599685669\n",
      "2.772200107574463\n",
      "2.7697861194610596\n",
      "2.767392158508301\n",
      "2.765018939971924\n",
      "2.7626655101776123\n",
      "2.760331153869629\n",
      "2.75801682472229\n",
      "2.755720853805542\n",
      "2.7534446716308594\n",
      "2.7511863708496094\n",
      "2.7489469051361084\n",
      "2.74672532081604\n",
      "2.7445216178894043\n",
      "2.742335557937622\n",
      "2.7401671409606934\n",
      "2.7380154132843018\n",
      "2.735881805419922\n",
      "2.7337639331817627\n",
      "2.7316629886627197\n",
      "2.7295784950256348\n",
      "2.7275097370147705\n",
      "2.725457191467285\n",
      "2.7234203815460205\n",
      "2.7213990688323975\n",
      "2.719393491744995\n",
      "2.717402458190918\n",
      "2.715426206588745\n",
      "2.7134652137756348\n",
      "2.7115190029144287\n",
      "2.7095866203308105\n",
      "2.7076687812805176\n",
      "2.7057650089263916\n",
      "2.7038748264312744\n",
      "2.701998710632324\n",
      "2.7001359462738037\n",
      "2.698286294937134\n",
      "2.6964502334594727\n",
      "2.694626808166504\n",
      "2.6928164958953857\n",
      "2.69101881980896\n",
      "2.6892337799072266\n",
      "2.6874613761901855\n",
      "2.6857011318206787\n",
      "2.683952569961548\n",
      "2.6822164058685303\n",
      "2.6804919242858887\n",
      "2.678779125213623\n",
      "2.6770777702331543\n",
      "2.6753883361816406\n",
      "2.6737096309661865\n",
      "2.67204213142395\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "for k in range(100):\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=729).float() # input to the network: one-hot encoding\n",
    "    logits = xenc @ W # this becomes just a row of W because of one-hot\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()\n",
    "    print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    W.data += -10 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\n",
      "sum: 0.9999998807907104\tshape: torch.Size([1, 27])\n",
      ".t\n",
      "sum: 0.9999999403953552\tshape: torch.Size([1, 27])\n",
      ".v\n",
      "sum: 0.9999999403953552\tshape: torch.Size([1, 27])\n",
      ".w\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".y\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".a\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".f\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".a\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".i\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".l\n",
      "sum: 0.9999998807907104\tshape: torch.Size([1, 27])\n",
      ".i\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".s\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".h\n",
      "sum: 1.0000001192092896\tshape: torch.Size([1, 27])\n",
      ".u\n",
      "sum: 0.9999999403953552\tshape: torch.Size([1, 27])\n",
      ".i\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".s\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".y\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".a\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".e\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".s\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".h\n",
      "sum: 1.0000001192092896\tshape: torch.Size([1, 27])\n",
      ".a\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".v\n",
      "sum: 0.9999999403953552\tshape: torch.Size([1, 27])\n",
      ".b\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".r\n",
      "sum: 0.9999998807907104\tshape: torch.Size([1, 27])\n",
      ".a\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".l\n",
      "sum: 0.9999998807907104\tshape: torch.Size([1, 27])\n",
      ".e\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".r\n",
      "sum: 0.9999998807907104\tshape: torch.Size([1, 27])\n",
      ".a\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".n\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".i\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".n\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".a\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".a\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".v\n",
      "sum: 0.9999999403953552\tshape: torch.Size([1, 27])\n",
      ".q\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".h\n",
      "sum: 1.0000001192092896\tshape: torch.Size([1, 27])\n",
      ".h\n",
      "sum: 1.0000001192092896\tshape: torch.Size([1, 27])\n",
      ".l\n",
      "sum: 0.9999998807907104\tshape: torch.Size([1, 27])\n",
      ".e\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".m\n",
      "sum: 0.9999998211860657\tshape: torch.Size([1, 27])\n",
      ".e\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".z\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".a\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".r\n",
      "sum: 0.9999998807907104\tshape: torch.Size([1, 27])\n",
      ".a\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".y\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".a\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".l\n",
      "sum: 0.9999998807907104\tshape: torch.Size([1, 27])\n",
      ".a\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".r\n",
      "sum: 0.9999998807907104\tshape: torch.Size([1, 27])\n",
      ".h\n",
      "sum: 1.0000001192092896\tshape: torch.Size([1, 27])\n",
      ".a\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".i\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".n\n",
      "sum: 1.0\tshape: torch.Size([1, 27])\n",
      ".o\n",
      "sum: 0.9999999403953552\tshape: torch.Size([1, 27])\n",
      ".t\n",
      "sum: 0.9999999403953552\tshape: torch.Size([1, 27])\n",
      "tvwyafailishuisyaeshavbraleraninaavqhhlemezarayalarhainot.\n"
     ]
    }
   ],
   "source": [
    "# Sampling\n",
    "g = torch.Generator().manual_seed(2147483647 + 2)\n",
    "\n",
    "for i in range(1):\n",
    "    out = []\n",
    "    ix = 0\n",
    "    \n",
    "    while True:\n",
    "        print(itos_2[ix])\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=729).float()\n",
    "        logits = xenc @ W # predict log-counts\n",
    "        counts = logits.exp()\n",
    "        p = counts / counts.sum(1, keepdims=True)\n",
    "        \n",
    "        print(f'sum: {torch.sum(p)}\\tshape: {p.shape}')\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itos[ix])\n",
    "        \n",
    "        if ix % 27 == 0:\n",
    "            break\n",
    "    # print(out)\n",
    "    print(''.join(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca06da50d752878786c990a9f7d2128b100a2bb6746b8dcab4d7eacf712457a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
